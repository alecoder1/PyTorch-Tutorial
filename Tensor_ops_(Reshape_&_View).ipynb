{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3To01RywMHokN8yfotJkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alecoder1/PyTorch-Tutorial/blob/main/Tensor_ops_(Reshape_%26_View).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differences between Reshape and View\n",
        "\n",
        "https://stackoverflow.com/questions/79025552/pytorch-difference-between-reshape-and-view-method/79026251#79026251"
      ],
      "metadata": {
        "id": "Ka12VK32pRdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3, 4, 5], dtype = torch.float32)\n",
        "x = x.reshape(-1, 1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD9GzNXrpjoo",
        "outputId": "18d775dc-6b61-43bc-809f-fac40687d8c9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.view(x.shape[0], 1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQqv5MHDpgf5",
        "outputId": "f89140f0-1475-4a6c-ae68-f15aaeb92f9c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The main difference is how torch.Tensor.reshape() and torch.Tensor.view() handle non-contiguous tensors.\n",
        "- To understand the difference, we need to understand what is a contiguous tensor, and what is a view of a tensor:\n",
        "- A contiguous tensor is a tensor whose values are stored in a single, uninterrupted – thus, \"contiguous\" – piece of memory. A non-contiguous tensor may have gaps in its memory layout.\n",
        "- Producing a view of a tensor means reinterpreting the arrangement of values in its memory. Think of a piece of memory that stores 16 values: we can interpret it, for example, as a 16-element 1-d tensor or as a 4×4-element 2-d tensor. Both interpretations can use the same underlying memory. By using views and thus reinterpreting the memory layout, we can create differently shaped tensors from the same piece of memory, in this way avoiding duplication and saving memory.\n",
        "Now back to the two methods:\n",
        "\n",
        "If applied to a contiguous tensor, both reshape() and view() will produce a new view of the given tensor's memory, in this way avoiding duplication.\n",
        "If applied to a non-contiguous tensor, the creation of a view will not be possible. The two methods handle this situation differently:\n",
        "The reshape() method will duplicate the necessary piece of memory and will return a tensor whose memory will not be shared with the given tensor.\n",
        "The view() method will produce a RuntimeError.\n",
        "We can demonstrate this with the following piece of code:\n"
      ],
      "metadata": {
        "id": "aj5jslPMqTuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import arange\n",
        "\n",
        "# Create contiguous 4×4 tensor\n",
        "contiguous = arange(16).view(4, 4)\n",
        "contiguous"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrhDOPGMriSU",
        "outputId": "cc891e9e-bf15-4959-a4c3-906f0caf4664"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create non-contiguous 4×4 tensor\n",
        "noncontiguous = arange(20).view(4, 5)[:, :4]\n",
        "noncontiguous"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joYbUeJGruAc",
        "outputId": "0a7c0d75-7060-4d54-b8ed-02ff4fd042ff"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 5,  6,  7,  8],\n",
              "        [10, 11, 12, 13],\n",
              "        [15, 16, 17, 18]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contiguous_r = contiguous.reshape(16)\n",
        "# OK: produces a 1-d view\n",
        "contiguous_r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhF0IMeWr4z7",
        "outputId": "e9eb2756-9905-4788-afae-d9f6cd801000"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same memory used\n",
        "assert contiguous_r.data_ptr() == contiguous.data_ptr() # Same memory used\n",
        "contiguous_r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQok1MIrsYFg",
        "outputId": "bff5f040-edab-426c-a551-b7bd57aefabe"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contiguous_v = contiguous.view(16)\n",
        "# OK: produces a 1-d view\n",
        "contiguous_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1jUaQUxseYH",
        "outputId": "35226ed1-c04c-4b6b-a937-6c5256204c01"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Same memory used\n",
        "assert contiguous_v.data_ptr() == contiguous.data_ptr()\n",
        "contiguous"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HucyID_s_kI",
        "outputId": "c853e230-3207-4c77-cf56-61acd9685804"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noncontiguous_r = noncontiguous.reshape(16)\n",
        "# OK: produces a new 1-d array\n",
        "noncontiguous_r"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBdsewG1tIss",
        "outputId": "c994eae7-e496-4a13-824d-3da2763003d8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  5,  6,  7,  8, 10, 11, 12, 13, 15, 16, 17, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New memory used\n",
        "assert noncontiguous_r.data_ptr() != noncontiguous.data_ptr()\n",
        "noncontiguous"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJ6J2Qc4tTmr",
        "outputId": "ae9be632-56f0-40c6-dbc3-a3ed5dbd92b8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 5,  6,  7,  8],\n",
              "        [10, 11, 12, 13],\n",
              "        [15, 16, 17, 18]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noncontiguous_v = noncontiguous.view(16)\n",
        "noncontiguous_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "Yi2sYBkPtZFL",
        "outputId": "75ff2f41-2fe5-402a-d505-f58bfe1c0ca5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3306961462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoncontiguous_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoncontiguous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnoncontiguous_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The last line will produce RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
        "- A tensor's stride is: in essence, it is the information that tells us how to map the tensor's indexes to its underlying memory."
      ],
      "metadata": {
        "id": "ckFpOTHZuSQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgTXPDAbt0qI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}